{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from baselines import logger\n",
    "from collections import deque\n",
    "from baselines.common import explained_variance, set_global_seeds\n",
    "from baselines.common.policies import build_policy\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "except ImportError:\n",
    "    MPI = None\n",
    "from baselines.ppo2.runner import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constfn(val):\n",
    "    def f(_):\n",
    "        return val\n",
    "    return f\n",
    "\n",
    "def learn(*, network, env, total_timesteps, test_mode = False, eval_env = None, seed=None, nsteps=2048, ent_coef=0.0, lr=3e-4,\n",
    "            vf_coef=0.5,  max_grad_norm=0.5, gamma=0.99, lam=0.95,\n",
    "            log_interval=10, nminibatches=4, noptepochs=4, cliprange=0.2,\n",
    "            save_interval=0, load_path=None, model_fn=None, update_fn=None, init_fn=None, mpi_rank_weight=1, comm=None, **network_kwargs):\n",
    "    '''\n",
    "    Learn policy using PPO algorithm (https://arxiv.org/abs/1707.06347)\n",
    "    Parameters:\n",
    "    ----------\n",
    "    network:                          policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n",
    "                                      specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n",
    "                                      tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n",
    "                                      neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n",
    "                                      See common/models.py/lstm for more details on using recurrent nets in policies\n",
    "    env: baselines.common.vec_env.VecEnv     environment. Needs to be vectorized for parallel environment simulation.\n",
    "                                      The environments produced by gym.make can be wrapped using baselines.common.vec_env.DummyVecEnv class.\n",
    "    nsteps: int                       number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n",
    "                                      nenv is number of environment copies simulated in parallel)\n",
    "    total_timesteps: int              number of timesteps (i.e. number of actions taken in the environment)\n",
    "    ent_coef: float                   policy entropy coefficient in the optimization objective\n",
    "    lr: float or function             learning rate, constant or a schedule function [0,1] -> R+ where 1 is beginning of the\n",
    "                                      training and 0 is the end of the training.\n",
    "    vf_coef: float                    value function loss coefficient in the optimization objective\n",
    "    max_grad_norm: float or None      gradient norm clipping coefficient\n",
    "    gamma: float                      discounting factor\n",
    "    lam: float                        advantage estimation discounting factor (lambda in the paper)\n",
    "    log_interval: int                 number of timesteps between logging events\n",
    "    nminibatches: int                 number of training minibatches per update. For recurrent policies,\n",
    "                                      should be smaller or equal than number of environments run in parallel.\n",
    "    noptepochs: int                   number of training epochs per update\n",
    "    cliprange: float or function      clipping range, constant or schedule function [0,1] -> R+ where 1 is beginning of the training\n",
    "                                      and 0 is the end of the training\n",
    "    save_interval: int                number of timesteps between saving events\n",
    "    load_path: str                    path to load the model from\n",
    "    **network_kwargs:                 keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n",
    "                                      For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n",
    "    '''\n",
    "\n",
    "    set_global_seeds(seed)\n",
    "\n",
    "    if isinstance(lr, float): lr = constfn(lr)\n",
    "    else: assert callable(lr)\n",
    "    if isinstance(cliprange, float): cliprange = constfn(cliprange)\n",
    "    else: assert callable(cliprange)\n",
    "    total_timesteps = int(total_timesteps)\n",
    "\n",
    "    policy = build_policy(env, network, **network_kwargs)\n",
    "\n",
    "    # Get the nb of env\n",
    "    nenvs = env.num_envs\n",
    "\n",
    "    # Get state_space and action_space\n",
    "    ob_space = env.observation_space\n",
    "    ac_space = env.action_space\n",
    "\n",
    "    # Calculate the batch_size\n",
    "    nbatch = nenvs * nsteps\n",
    "    nbatch_train = nbatch // nminibatches\n",
    "    is_mpi_root = (MPI is None or MPI.COMM_WORLD.Get_rank() == 0)\n",
    "\n",
    "    # Instantiate the model object (that creates act_model and train_model)\n",
    "    if model_fn is None:\n",
    "        from baselines.ppo2.model import Model\n",
    "        model_fn = Model\n",
    "\n",
    "    model = model_fn(policy=policy, ob_space=ob_space, ac_space=ac_space, nbatch_act=nenvs, nbatch_train=nbatch_train,\n",
    "                    nsteps=nsteps, ent_coef=ent_coef, vf_coef=vf_coef,\n",
    "                    max_grad_norm=max_grad_norm, comm=None, mpi_rank_weight=mpi_rank_weight)\n",
    "\n",
    "    if load_path is not None:\n",
    "        model.load(load_path)\n",
    "    # Instantiate the runner object\n",
    "    runner = Runner(env=env, model=model, nsteps=nsteps, gamma=gamma, lam=lam)\n",
    "    if eval_env is not None:\n",
    "        eval_runner = Runner(env = eval_env, model = model, nsteps = nsteps, gamma = gamma, lam= lam)\n",
    "\n",
    "    epinfobuf = deque(maxlen=100)\n",
    "    if eval_env is not None:\n",
    "        eval_epinfobuf = deque(maxlen=100)\n",
    "\n",
    "    if init_fn is not None:\n",
    "        init_fn()\n",
    "\n",
    "    # Start total timer\n",
    "    tfirststart = time.perf_counter()\n",
    "\n",
    "    nupdates = total_timesteps//nbatch\n",
    "    for update in range(1, nupdates+1):\n",
    "        assert nbatch % nminibatches == 0\n",
    "        # Start timer\n",
    "        tstart = time.perf_counter()\n",
    "        frac = 1.0 - (update - 1.0) / nupdates\n",
    "        # Calculate the learning rate\n",
    "        lrnow = lr(frac)\n",
    "        # Calculate the cliprange\n",
    "        cliprangenow = cliprange(frac)\n",
    "\n",
    "        if update % log_interval == 0 and is_mpi_root: logger.info('Stepping environment...')\n",
    "\n",
    "        # Get minibatch\n",
    "        obs, returns, masks, actions, values, neglogpacs, states, epinfos = runner.run() #pylint: disable=E0632\n",
    "        if eval_env is not None:\n",
    "            eval_obs, eval_returns, eval_masks, eval_actions, eval_values, eval_neglogpacs, eval_states, eval_epinfos = eval_runner.run() #pylint: disable=E0632\n",
    "\n",
    "        if update % log_interval == 0 and is_mpi_root: logger.info('Done.')\n",
    "\n",
    "        epinfobuf.extend(epinfos)\n",
    "        if eval_env is not None:\n",
    "            eval_epinfobuf.extend(eval_epinfos)\n",
    "\n",
    "        if test_mode == False:\n",
    "            # Here what we're going to do is for each minibatch calculate the loss and append it.\n",
    "            mblossvals = []\n",
    "            if states is None: # nonrecurrent version\n",
    "                # Index of each element of batch_size\n",
    "                # Create the indices array\n",
    "                inds = np.arange(nbatch)\n",
    "                for _ in range(noptepochs):\n",
    "                    # Randomize the indexes\n",
    "                    np.random.shuffle(inds)\n",
    "                    # 0 to batch_size with batch_train_size step\n",
    "                    for start in range(0, nbatch, nbatch_train):\n",
    "                        end = start + nbatch_train\n",
    "                        mbinds = inds[start:end]\n",
    "                        slices = (arr[mbinds] for arr in (obs, returns, masks, actions, values, neglogpacs))\n",
    "                        mblossvals.append(model.train(lrnow, cliprangenow, *slices))\n",
    "            else: # recurrent version\n",
    "                assert nenvs % nminibatches == 0\n",
    "                envsperbatch = nenvs // nminibatches\n",
    "                envinds = np.arange(nenvs)\n",
    "                flatinds = np.arange(nenvs * nsteps).reshape(nenvs, nsteps)\n",
    "                for _ in range(noptepochs):\n",
    "                    np.random.shuffle(envinds)\n",
    "                    for start in range(0, nenvs, envsperbatch):\n",
    "                        end = start + envsperbatch\n",
    "                        mbenvinds = envinds[start:end]\n",
    "                        mbflatinds = flatinds[mbenvinds].ravel()\n",
    "                        slices = (arr[mbflatinds] for arr in (obs, returns, masks, actions, values, neglogpacs))\n",
    "                        mbstates = states[mbenvinds]\n",
    "                        mblossvals.append(model.train(lrnow, cliprangenow, *slices, mbstates))\n",
    "\n",
    "            # Feedforward --> get losses --> update\n",
    "            lossvals = np.mean(mblossvals, axis=0)\n",
    "            print(\"training\")\n",
    "            \n",
    "        # End timer\n",
    "        tnow = time.perf_counter()\n",
    "        # Calculate the fps (frame per second)\n",
    "        fps = int(nbatch / (tnow - tstart))\n",
    "\n",
    "        if update_fn is not None:\n",
    "            update_fn(update)\n",
    "\n",
    "        if update % log_interval == 0 or update == 1:\n",
    "            # Calculates if value function is a good predicator of the returns (ev > 1)\n",
    "            # or if it's just worse than predicting nothing (ev =< 0)\n",
    "            ev = explained_variance(values, returns)\n",
    "            logger.logkv(\"misc/serial_timesteps\", update*nsteps)\n",
    "            logger.logkv(\"misc/nupdates\", update)\n",
    "            logger.logkv(\"misc/total_timesteps\", update*nbatch)\n",
    "            logger.logkv(\"fps\", fps)\n",
    "            logger.logkv(\"misc/explained_variance\", float(ev))\n",
    "            logger.logkv('eprewmean', safemean([epinfo['r'] for epinfo in epinfobuf]))\n",
    "            logger.logkv('eplenmean', safemean([epinfo['l'] for epinfo in epinfobuf]))\n",
    "            if eval_env is not None:\n",
    "                logger.logkv('eval_eprewmean', safemean([epinfo['r'] for epinfo in eval_epinfobuf]) )\n",
    "                logger.logkv('eval_eplenmean', safemean([epinfo['l'] for epinfo in eval_epinfobuf]) )\n",
    "            logger.logkv('misc/time_elapsed', tnow - tfirststart)\n",
    "            if test_mode == False:\n",
    "                for (lossval, lossname) in zip(lossvals, model.loss_names):\n",
    "                    logger.logkv('loss/' + lossname, lossval)\n",
    "\n",
    "            logger.dumpkvs()\n",
    "        if save_interval and (update % save_interval == 0 or update == 1) and logger.get_dir() and is_mpi_root:\n",
    "            checkdir = osp.join(logger.get_dir(), 'checkpoints')\n",
    "            os.makedirs(checkdir, exist_ok=True)\n",
    "            savepath = osp.join(checkdir, '%.5i'%update)\n",
    "            print('Saving to', savepath)\n",
    "            model.save(savepath)\n",
    "\n",
    "    return model\n",
    "# Avoid division error when calculate the mean (in our case if epinfo is empty returns np.nan, not return an error)\n",
    "def safemean(xs):\n",
    "    return np.nan if len(xs) == 0 else np.mean(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from baselines.ppo2 import ppo2\n",
    "from baselines.common.models import build_impala_cnn\n",
    "from baselines.common.mpi_util import setup_mpi_gpus\n",
    "from procgen import ProcgenEnv\n",
    "from baselines.common.vec_env import (\n",
    "    VecExtractDictObs,\n",
    "    VecMonitor,\n",
    "    VecFrameStack,\n",
    "    VecNormalize\n",
    ")\n",
    "from baselines import logger\n",
    "# from mpi4py import MPI\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 16\n",
    "learning_rate = 5e-4\n",
    "ent_coef = .01\n",
    "gamma = .999\n",
    "lam = .95\n",
    "nsteps = 256\n",
    "nminibatches = 8\n",
    "ppo_epochs = 3\n",
    "clip_range = .2\n",
    "use_vf_clipping = True\n",
    "run_dir = \".\"\n",
    "env_name = 'fruitbot'\n",
    "distribution_mode = 'easy'\n",
    "start_level = 0\n",
    "num_levels = 50\n",
    "timesteps_per_proc = 10000\n",
    "test_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to .\n",
      "creating environment\n",
      "creating tf session\n",
      "num_levels 50\n",
      "training\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/mpi_adam_optimizer.py:11: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/ppo2/model.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/ppo2/model.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/input.py:31: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/models.py:43: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/models.py:57: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/models.py:67: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/models.py:69: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/a2c/utils.py:61: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/distributions.py:200: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/distributions.py:201: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/ppo2/model.py:95: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/tf_util.py:89: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/common/tf_util.py:90: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/ppo2/model.py:129: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rzhang/opt/anaconda3/envs/finalproject/lib/python3.7/site-packages/baselines/ppo2/model.py:129: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 81.1     |\n",
      "| eprewmean               | -3.43    |\n",
      "| fps                     | 872      |\n",
      "| misc/explained_variance | -0.0548  |\n",
      "| misc/nupdates           | 1        |\n",
      "| misc/serial_timesteps   | 256      |\n",
      "| misc/time_elapsed       | 4.7      |\n",
      "| misc/total_timesteps    | 4.1e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 79.2     |\n",
      "| eprewmean               | -2.87    |\n",
      "| fps                     | 941      |\n",
      "| misc/explained_variance | -0.0544  |\n",
      "| misc/nupdates           | 2        |\n",
      "| misc/serial_timesteps   | 512      |\n",
      "| misc/time_elapsed       | 9.05     |\n",
      "| misc/total_timesteps    | 8.19e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baselines.ppo2.model.Model at 0x1389a49d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_strs = ['csv', 'stdout']\n",
    "logger.configure(dir=run_dir, format_strs=format_strs)\n",
    "\n",
    "logger.info(\"creating environment\")\n",
    "venv = ProcgenEnv(num_envs=num_envs, env_name=env_name, num_levels=num_levels, start_level=start_level, distribution_mode=distribution_mode)\n",
    "venv = VecExtractDictObs(venv, \"rgb\")\n",
    "\n",
    "venv = VecMonitor(\n",
    "    venv=venv, filename=None, keep_buf=100,\n",
    ")\n",
    "\n",
    "venv = VecNormalize(venv=venv, ob=False)\n",
    "\n",
    "logger.info(\"creating tf session\")\n",
    "setup_mpi_gpus()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True #pylint: disable=E1101\n",
    "sess = tf.Session(config=config)\n",
    "sess.__enter__()\n",
    "\n",
    "conv_fn = lambda x: build_impala_cnn(x, depths=[16,32,32], emb_size=256)\n",
    "print(\"num_levels\", num_levels)\n",
    "logger.info(\"training\")\n",
    "learn(\n",
    "    env=venv,\n",
    "    network=conv_fn,\n",
    "    total_timesteps=timesteps_per_proc,\n",
    "    test_mode = test_mode,\n",
    "    save_interval=0,\n",
    "    nsteps=nsteps,\n",
    "    nminibatches=nminibatches,\n",
    "    lam=lam,\n",
    "    gamma=gamma,\n",
    "    noptepochs=ppo_epochs,\n",
    "    log_interval=1,\n",
    "    ent_coef=ent_coef,\n",
    "    mpi_rank_weight=1,\n",
    "    clip_vf=use_vf_clipping,\n",
    "    comm=None,\n",
    "    lr=learning_rate,\n",
    "    cliprange=clip_range,\n",
    "    update_fn=None,\n",
    "    init_fn=None,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    load_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Test_mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01f1badaec69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTest_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Test_mode' is not defined"
     ]
    }
   ],
   "source": [
    "Test_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 procgen",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
